{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e0845bc1-7663-4dcf-ae3d-7beacce381f3",
   "metadata": {},
   "source": [
    "# Tema 5 \n",
    "### Regresión lineal."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "527cd1f8-5893-44ec-b4f6-daf525b89348",
   "metadata": {},
   "source": [
    "# <a id=\"ind\"></a> Índice:\n",
    "- [5.1 Regresión y correlación](#regresion-y-correlacion)\n",
    "  - [5.1.1 Diagrama de dispersión](#diagrama-de-dispersion)\n",
    "  - [5.1.2 Regresión lineal simple](#regresion-lineal-simple)\n",
    "  - [5.1.3 Correlación](#correlacion)\n",
    "  - [5.1.4 Determinación y análisis de los coeficientes de correlación y determinación](#analisis-coeficientes)\n",
    "  - [5.1.5 Distribución normal bidimensional](#distribucion-normal-bidimensional)\n",
    "  - [5.1.6 Intervalos de confianza y pruebas para el coeficiente de correlación](#intervalos-confianza-correlacion)\n",
    "  - [5.1.7 Errores de medición](#errores-de-medicion)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc443a6e-cc4e-474e-8035-b2fd18120cee",
   "metadata": {},
   "source": [
    "[Siguiente](#diagrama-de-dispersion) ||\n",
    "[Volver al Menú](#ind)\n",
    "# <a id=\"regresion-y-correlacion\"></a> 5.1 Regresión y correlación.\n",
    "En estadística, estos dos conceptos estan estrechamente relacionados pero con objetivos ligeramente diferentres. Ambos se utilizan para analizar la relación entre dos o más variables, pero la regresión va un paso más allá al intentar modelar esa relación.\n",
    "### Correlación.\n",
    "La correlación mide la fuerza y la dirección de la relación lineal entre dos variables. En otras palabras, nos indica si al aumentar una variable, la otra tiende a aumentar (correlación positiva), disminuir (correlación negativa) o si no existe una relación lineal entre ellas.\n",
    "\n",
    "### ¿Cómo se mide?\n",
    "El coeficiente de correlación de Pearson (r) es el estadístico más comúnmente utilizado para medir la correlación lineal. Este coeficiente varía entre -1 y 1:\n",
    "\n",
    "\n",
    "$$\n",
    "r = \\frac{\\sum_{i=1}^{n} (x_i - \\bar{x})(y_i - \\bar{y})}{\\sqrt{\\sum_{i=1}^{n} (x_i - \\bar{x})^2 \\sum_{i=1}^{n} (y_i - \\bar{y})^2}}\n",
    "$$\n",
    "\n",
    "### ¿Qué significa cada parte de la fórmula?\n",
    "\n",
    "- r: Representa el coeficiente de correlación de Pearson.\n",
    "- x_i: Es el valor individual de la variable X en la observación i.\n",
    "- y_i: Es el valor individual de la variable Y en la observación i.\n",
    "- x̄: Es la media de la variable X.\n",
    "- ȳ: Es la media de la variable Y.\n",
    "- Σ: Es el símbolo de sumatoria, que indica que se suman todos los valores desde i=1 hasta i=n.\n",
    "- n: Es el número total de observaciones.\n",
    "### ¿Cómo se interpreta el resultado?\n",
    "- r = 1: Correlación positiva perfecta.\n",
    "- r = -1: Correlación negativa perfecta.\n",
    "- r = 0: No existe correlación lineal.\n",
    "\n",
    "### Regresión.\n",
    "La regresión busca encontrar la mejor línea (o curva) que se ajuste a los datos y que permita predecir el valor de una variable en función de otra. En otras palabras, la regresión nos permite modelar la relación entre variables y hacer predicciones.\n",
    "\n",
    "![Regresión](imagen_1.png)\n",
    "\n",
    "### ¿Para que sirve?\n",
    "La regresión se utiliza en una amplia variedad de campos, como economía, finanzas, ciencias sociales, etc. Algunos ejemplos de aplicaciones incluyen:\n",
    "- Predecir el precio de una vivienda en función de su tamaño y ubicación.\n",
    "- Estimar el consumo de energía de un hogar en función de la temperatura exterior.\n",
    "- Analizar el impacto de la publicidad en las ventas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4e48a68-8220-48e6-a2bd-251df3293ada",
   "metadata": {},
   "source": [
    "[Siguiente](#regresion-lineal-simple) ||\n",
    "[Volver al Menú](#ind)\n",
    "### <a id=\"diagrama-de-dispersion\"></a>5.1.1 Diagrama de dispersión\n",
    "Un diagrama de dispersión es una gráfica de puntos representados en el plano cartesiano. Cada punto indica un par de valores (x, y). Este diagrama permite observar cómo se relacionan dos variables; generalmente, lo que se busca al usar un diagrama de este tipo es determinar si los puntos siguen una línea recta y si ésta tiene pendiente positiva o negativa.\n",
    "\n",
    "![Diagrama de dispersión](imagen_2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7197b5b-a1af-48a8-be73-02a6cf61ea16",
   "metadata": {},
   "source": [
    "[Siguiente](#correlacion) ||\n",
    "[Volver al Menú](#ind)\n",
    "### <a id=\"regresion-lineal-simple\"></a>5.1.2 Regresión lineal simple.\n",
    "El método de regresión lineal simple recibe este nombre, por que:\n",
    "- _Regresión_: utilizaremos información pasada\n",
    "- _Lineal_: bajo el supuesto de que entre dos variables (X y Y) existe una relación lineal\n",
    "- _simple_: usaremos sólo una variable independiente para tratar de explicar la variable dependiente.\n",
    "\n",
    "En otras palabras, ajustaremos una recta a los datos. \"Ajustar\"se refiera a construir la única recta que pase por lo mas cerca de todos los puntos ubicados en el diagrama de dispersión.\n",
    "\n",
    "La regresión lineal simple se utiliza para modelar la relación lineal entre dos variables cuantitativas. La ecuación general de una recta es:\n",
    "\n",
    "$$\n",
    "y = a + bx\n",
    "$$\n",
    "\n",
    "Donde:\n",
    "- y: Variable dependiente.\n",
    "- x: Variable independiente.\n",
    "- a: Intersección con el eje y.\n",
    "- b: Pendiente de la recta.\n",
    "\n",
    "#### Estimación de los parámetros a y b\n",
    "Para encontrar los valores específicos de a y b que mejor se ajustan a nuestros datos, utilizamos el método de mínimos cuadrados ordinarios. Las fórmulas para calcular estos parámetros son las siguientes:\n",
    "\n",
    "$$\n",
    "b = \\frac{\\sum_{i=1}^{n} (x_i - \\bar{x})(y_i - \\bar{y})}{\\sum_{i=1}^{n} (x_i - \\bar{x})^2}\n",
    "$$\n",
    "$$\n",
    "a = \\bar{y} - b \\bar{x}\n",
    "$$\n",
    "\n",
    "Donde:\n",
    "- xi: Valor individual de la variable x.\n",
    "- yi: Valor individual de la variable y.\n",
    "- x̄: Media de la variable x.\n",
    "- ȳ: Media de la variable y.\n",
    "- Σ: Significa sumatoria.\n",
    "- n: Número total de observaciones."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0c64c3a-b934-488a-8027-68b4ba6193d1",
   "metadata": {},
   "source": [
    "[Siguiente](#analisis-coeficientes) ||\n",
    "[Volver al Menú](#ind)\n",
    "### <a id=\"correlacion\"></a>5.1.3 Correlación\n",
    "La correlación mide la relación entre dos variables y cómo cambian juntas: si aumentan o disminuyen al mismo tiempo (**positiva**), si una sube mientras la otra baja (**negativa**) o si no tienen relación (**nula**). Se mide con el coeficiente de Pearson (\\(r\\)), que varía entre \\(-1\\) (relación negativa perfecta), \\(0\\) (sin relación) y \\(1\\) (relación positiva perfecta). Aunque es útil para análisis predictivo y detectar patrones, la correlación no implica causalidad.\n",
    "\n",
    "Formula:\n",
    "$$r = \\frac{\\sum_{i=1}^{n} (x_i - \\bar{x})(y_i - \\bar{y})}{\\sqrt{\\sum_{i=1}^{n} (x_i - \\bar{x})^2 \\sum_{i=1}^{n} (y_i - \\bar{y})^2}}$$\n",
    "\n",
    "Dónde:\n",
    "- r: Coeficiente de correlación de Pearson.\n",
    "- xᵢ: Valor individual de la variable X en la observación i.\n",
    "- yᵢ: Valor individual de la variable Y en la observación i.\n",
    "- x̄: Media de la variable X.\n",
    "- ȳ: Media de la variable Y.\n",
    "- Σ: Signo de sumatoria.\n",
    "- n: Número total de observaciones."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2f6a7c1-8b5e-4384-a5f4-b4a8b8dfae8a",
   "metadata": {},
   "source": [
    "[Siguiente](#distribucion-normal-bidimensional) ||\n",
    "[Volver al Menú](#ind)\n",
    "### <a id=\"analisis-coeficientes\"></a>5.1.4 Determinación y análisis de los coeficientes de correlación y determinación.\n",
    "El coeficiente de correlación (r) nos indica qué tan fuerte y en qué dirección se relacionan dos variables. Un valor cercano a 1 o -1 sugiere una relación muy fuerte, mientras que uno cercano a 0 indica una relación débil o nula. Por su parte, el coeficiente de determinación (R²) nos dice qué proporción de la variabilidad de una variable puede explicarse por otra. Un R² alto significa que el modelo de regresión utilizado es bueno para predecir los valores de la variable dependiente. En conjunto, estos coeficientes nos permiten evaluar la calidad de un modelo y comprender mejor la relación entre las variables que estamos estudiando.\n",
    "\n",
    "#### ¿Cómo se calcula el coeficiente de determinación?\n",
    "El coeficiente de determinación es simplemente el cuadrado del coeficiente de correlación:\n",
    "$$\n",
    "R^2 = r^2\n",
    "$$\n",
    "\n",
    "#### ¿Qué nos dice el coeficiente de determinación?\n",
    "- **Bondad de ajuste:** Un valor de R² cercano a 1 indica que el modelo de regresión lineal explica una gran proporción de la variabilidad en la variable dependiente.\n",
    "- **Porcentaje de varianza explicada:** R² se puede interpretar como el porcentaje de la varianza en la variable dependiente que es explicada por la variable independiente.\n",
    "\n",
    "#### Análisis de los Coeficientes\n",
    "Al interpretar los coeficientes de correlación y determinación, es importante considerar:\n",
    "- **Significancia estadística:** Es necesario realizar una prueba de hipótesis para determinar si la correlación es estadísticamente significativa. Esto nos indica si la relación observada es probable que se deba al azar o si es un resultado real.\n",
    "- **Causalidad:** La correlación no implica causalidad. Es decir, el hecho de que dos variables estén correlacionadas no significa necesariamente que una cause la otra.1 Podría haber una tercera variable influyendo en ambas.\n",
    "- **Otros factores:** Es importante considerar otros factores que podrían estar influyendo en la relación entre las variables, como variables omitidas o errores de medición.\n",
    "- **Visualización:** Un gráfico de dispersión puede ser muy útil para visualizar la relación entre las variables y evaluar si la relación es realmente lineal."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5925388c-1187-4d33-857d-95c2918c0b0b",
   "metadata": {},
   "source": [
    "[Siguiente](#intervalos-confianza-correlacion) ||\n",
    "[Volver al Menú](#ind)\n",
    "### <a id=\"distribucion-normal-bidimensional\"></a>5.1.5 Distribución normal bidimensional \n",
    "La distribución normal bidimensional es una herramienta estadística que nos permite modelar la relación entre dos variables continuas que siguen una distribución normal y están linealmente relacionadas. Imagina una nube de puntos en un gráfico de dispersión: si esta nube tiene forma de elipse y los puntos se distribuyen de manera más densa hacia el centro, es probable que estemos ante una distribución normal bidimensional. Esta distribución se define por cinco parámetros: las medias de cada variable, sus desviaciones estándar y el coeficiente de correlación que mide la fuerza y dirección de la relación entre ellas. Es ampliamente utilizada en diversos campos, como finanzas, economía y ciencias sociales, para analizar y predecir fenómenos que involucran dos variables continuas.\n",
    "\n",
    "La función de densidad de probabilidad (FDP) de una distribución normal bidimensional es:\n",
    "$$\n",
    "f(x, y) = \\frac{1}{2\\pi\\sigma_x\\sigma_y\\sqrt{1-\\rho^2}} \\exp\\left(-\\frac{1}{2(1-\\rho^2)}\\left[\\left(\\frac{x-\\mu_x}{\\sigma_x}\\right)^2 - 2\\rho\\left(\\frac{x-\\mu_x}{\\sigma_x}\\right)\\left(\\frac{y-\\mu_y}{\\sigma_y}\\right) + \\left(\\frac{y-\\mu_y}{\\sigma_y}\\right)^2\\right]\\right)\n",
    "$$\n",
    "Dónde:\n",
    "- x e y: Variables aleatorias continuas.\n",
    "- μx y μy: Medias de las variables X e Y, respectivamente.\n",
    "- σx y σy: Desviaciones estándar de las variables X e Y, respectivamente.\n",
    "- ρ: Coeficiente de correlación entre X e Y.\n",
    "- π: Constante matemática pi.\n",
    "- e: Base del logaritmo natural."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dc410f0-ff8a-4b8d-82d6-1bf5982bd6af",
   "metadata": {},
   "source": [
    "[Siguiente](#errores-de-medicion) ||\n",
    "[Volver al Menú](#ind)\n",
    "### <a id=\"intervalos-confianza-correlacion\"></a>5.1.6 Intervalos de confianza y pruebas para el coeficiente de correlación\n",
    "Cuando calculamos el coeficiente de correlación (r) a partir de una muestra, estamos estimando la correlación real entre dos variables en toda la población. Sin embargo, esta estimación tiene un margen de error.\n",
    "\n",
    "- **Intervalos de confianza:** Nos permiten establecer un rango de valores dentro del cual, con cierta seguridad (por ejemplo, 95%), se encuentra el verdadero valor de la correlación en la población. Es como decir: \"Estamos 95% seguros de que la correlación real está entre estos dos valores\".\n",
    "- **Pruebas de hipótesis:** Nos ayudan a determinar si la correlación que observamos en la muestra es lo suficientemente fuerte como para concluir que existe una relación real entre las variables en la población. En otras palabras, si la correlación que encontramos no se debe solo al azar.\n",
    "\n",
    "Entonces:\n",
    "- **Intervalos de confianza:** Muestran la precisión de nuestra estimación.\n",
    "- **Pruebas de hipótesis:** Evaluan la significancia estadística de la correlación.\n",
    "\n",
    "Ambos conceptos son fundamentales para interpretar correctamente los resultados de un análisis de correlación y tomar decisiones basadas en los datos.\n",
    "\n",
    "#### Transformación de Fisher\n",
    "Uno de los métodos más comunes para construir intervalos de confianza para el coeficiente de correlación de Pearson es la transformación de Fisher. Esta transformación convierte el coeficiente de correlación en una variable que sigue aproximadamente una distribución normal.\n",
    "$$\n",
    "z = \\frac{1}{2}\\ln\\left(\\frac{1+r}{1-r}\\right)\n",
    "$$\n",
    "\n",
    "Donde:\n",
    "- z: Valor transformado que sigue aproximadamente una distribución normal.\n",
    "- r: Coeficiente de correlación de Pearson.\n",
    "- ln: Logaritmo natural.\n",
    "\n",
    "- **Intervalo de confianza para z:**\n",
    "  \n",
    "   Se construye un intervalo de confianza para z utilizando la distribución normal estándar.\n",
    "- **Volver a transformar:**\n",
    "  \n",
    "  Se transforma el intervalo de confianza de z nuevamente a la escala original del coeficiente de correlación.\n",
    "\n",
    "#### Prueba t para el coeficiente de correlación:\n",
    "Estadístico de prueba:\n",
    "$$\n",
    "t = \\frac{r\\sqrt{n-2}}{\\sqrt{1-r^2}}\n",
    "$$\n",
    "Donde:\n",
    "- t: Estadístico t.\n",
    "- r: Coeficiente de correlación de Pearson.\n",
    "- n: Tamaño de la muestra.\n",
    "- Grados de libertad: n - 2.\n",
    "- Valor p: Se compara el valor calculado de t con la distribución t de Student con n - 2 grados de libertad para obtener el valor p"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7e70fd6-a25a-428f-bb3c-bd740910a643",
   "metadata": {},
   "source": [
    "[Volver al Menú](#ind)\n",
    "### <a id=\"errores-de-medicion\"></a>5.1.7 Errores de medición\n",
    "Los errores de medición son las desviaciones que ocurren entre el valor real de una cantidad y el valor que obtenemos al medirla. Estos errores son inevitables y pueden ser de dos tipos principales:\n",
    "\n",
    "- **Errores sistemáticos:** Son errores constantes que desplazan todas las mediciones en una misma dirección. Pueden ser causados por problemas en el instrumento, condiciones ambientales o el método de medición.\n",
    "- **Errores aleatorios:** Son errores impredecibles que varían de una medición a otra. Pueden surgir por fluctuaciones en las condiciones, limitaciones del instrumento o errores humanos.\n",
    "  \n",
    "**¿Por qué son importantes los errores de medición?**\n",
    "\n",
    "Afectan la precisión de los resultados.\n",
    "Pueden llevar a conclusiones erróneas.\n",
    "Implican pérdidas de tiempo y recursos.\n",
    "\n",
    "**¿Cómo podemos reducir los errores de medición?**\n",
    "- Calibrando los instrumentos.\n",
    "- Utilizando instrumentos adecuados.\n",
    "- Controlando las condiciones ambientales.\n",
    "- Repitiendo las mediciones.\n",
    "- Aplicando métodos estadísticos.\n",
    "  \n",
    "Los errores de medición son algo que debemos tener en cuenta en cualquier proceso de medición. Al comprender sus causas y aplicar las técnicas adecuadas, podemos minimizar su impacto y obtener resultados más confiables.\n",
    "\n",
    "#### Fórmulas básicas:\n",
    "La forma en que se propaga la incertidumbre depende de la operación matemática que se está realizando. A continuación, se presentan algunas de las fórmulas más comunes:\n",
    "\n",
    "Suma y resta:\n",
    "Si z = x + y, entonces:\n",
    "\n",
    "$$\n",
    "\\delta z = \\sqrt{\\delta x^2 + \\delta y^2}\n",
    "$$\n",
    "\n",
    "Donde:\n",
    "- δz: Incertidumbre en z\n",
    "- δx: Incertidumbre en x\n",
    "- δy: Incertidumbre en y\n",
    "  \n",
    "**Multiplicación y división:**\n",
    "\n",
    "Si z = x * y, entonces:\n",
    "\n",
    "$$\n",
    "\\left(\\frac{\\delta z}{z}\\right)^2 = \\left(\\frac{\\delta x}{x}\\right)^2 + \\left(\\frac{\\delta y}{y}\\right)^2\n",
    "$$\n",
    "\n",
    "**Funciones:**\n",
    "\n",
    "Para funciones más complejas, se utiliza la propagación de errores basada en derivadas parciales. Por ejemplo, si z = f(x, y), entonces:\n",
    "\n",
    "$$\n",
    "\\delta z^2 = \\left(\\frac{\\partial f}{\\partial x}\\right)^2 \\delta x^2 + \\left(\\frac{\\partial f}{\\partial y}\\right)^2 \\delta y^2\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f39752a0-05df-4b6b-828b-98a784d603f5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
